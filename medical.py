# -*- coding: utf-8 -*-
"""medical

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KCi0jubQ1HdGdz5dFm3wVGs33V-bHM1S
"""



# ========================================
# MEDICAL AI ASSISTANT - NO INSTALLATION VERSION
# Uses only pre-installed Colab packages
# Copy and paste this entire cell in Google Colab
# ========================================

print("üöÄ Starting Medical AI Assistant...")
print("‚úÖ Using pre-installed packages only - No installation needed!\n")

# Import libraries (all pre-installed in Colab)
import gradio as gr
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer
import torch
from PIL import Image
import numpy as np
import warnings
warnings.filterwarnings('ignore')

print("üìö Libraries loaded successfully!\n")

# Configuration
print("‚öôÔ∏è Configuration...")
MODEL_NAME = "ibm-granite/granite-3.3-2b-instruct"
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üñ•Ô∏è Using device: {device}\n")

# Load Model
print("ü§ñ Loading IBM Granite 3.3 2B model...")
print("‚è≥ First time: ~2-3 minutes (downloading model)")
print("‚è≥ Subsequent runs: ~30 seconds (cached)\n")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        device_map="auto" if device == "cuda" else None,
        low_cpu_mem_usage=True
    )

    if device == "cpu":
        model = model.to(device)

    print("‚úÖ Model loaded successfully!\n")
except Exception as e:
    print(f"‚ùå Error: {e}\n")
    raise

print("="*50)
print("üéâ ALL SYSTEMS READY!")
print("="*50 + "\n")

# ========================================
# CORE FUNCTIONS
# ========================================

def chat_with_bot(message, history):
    """Medical chatbot with conversation history"""
    try:
        if not message.strip():
            return "Please enter a question."

        # Build conversation
        conversation = "You are a helpful medical AI assistant. Provide clear, accurate medical information. Always remind users to consult healthcare professionals.\n\n"

        # Add recent history
        recent_history = history[-5:] if len(history) > 5 else history
        for user_msg, bot_msg in recent_history:
            conversation += f"User: {user_msg}\nAssistant: {bot_msg}\n"

        conversation += f"User: {message}\nAssistant:"

        # Generate response
        inputs = tokenizer(conversation, return_tensors="pt", truncation=True, max_length=1024).to(device)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=250,
                temperature=0.7,
                do_sample=True,
                top_p=0.9,
                pad_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        if "Assistant:" in response:
            response = response.split("Assistant:")[-1].strip()

        return response if response else "I couldn't generate a response. Please try again."

    except Exception as e:
        return f"‚ö†Ô∏è Error: {str(e)}"

def simple_ocr(image):
    """Simple text extraction from prescription images"""
    try:
        if image is None:
            return "‚ùå Please upload an image first."

        # Convert to PIL Image
        if isinstance(image, str):
            img = Image.open(image)
        elif isinstance(image, np.ndarray):
            img = Image.fromarray(image.astype('uint8'))
        else:
            img = image

        # For now, provide instructions since we can't install OCR
        return """üìÑ **Prescription Image Uploaded Successfully!**

‚ö†Ô∏è **OCR Feature Unavailable** (requires package installation)

**Manual Text Extraction Options:**
1. **Use Google Lens**: Take a photo and use Google Lens to extract text
2. **Type it manually**: Copy the text from your prescription
3. **Online OCR**: Use free tools like:
   - https://www.onlineocr.net/
   - https://www.newocr.com/

**Then paste the extracted text in the chatbot** and ask questions about it!

**Tip**: You can ask the chatbot things like:
- "What is [medicine name] used for?"
- "What are the side effects of [medicine]?"
- "When should I take [medicine]?" """

    except Exception as e:
        return f"‚ö†Ô∏è Error: {str(e)}"

def suggest_alternatives(drug_name):
    """Suggest alternative medications"""
    try:
        if not drug_name.strip():
            return "‚ùå Please enter a medication name."

        # Comprehensive alternatives database
        alternatives_db = {
            "paracetamol": ["Acetaminophen", "Tylenol", "Crocin", "Dolo 650", "Calpol"],
            "acetaminophen": ["Paracetamol", "Tylenol", "Crocin", "Dolo 650"],
            "ibuprofen": ["Advil", "Motrin", "Nurofen", "Brufen", "Combiflam"],
            "amoxicillin": ["Augmentin", "Ampicillin", "Cephalexin", "Azithromycin"],
            "metformin": ["Glucophage", "Glumetza", "Fortamet", "Glycomet"],
            "aspirin": ["Disprin", "Ecosprin", "Acetylsalicylic acid", "Aspro Clear"],
            "omeprazole": ["Prilosec", "Pantoprazole", "Esomeprazole", "Rabeprazole"],
            "atorvastatin": ["Lipitor", "Rosuvastatin", "Simvastatin", "Pravastatin"],
            "losartan": ["Cozaar", "Telmisartan", "Valsartan", "Olmesartan"],
            "cetirizine": ["Zyrtec", "Loratadine", "Fexofenadine", "Allegra"],
            "amlodipine": ["Norvasc", "Nifedipine", "Felodipine", "Diltiazem"],
            "lisinopril": ["Enalapril", "Ramipril", "Perindopril", "Captopril"],
            "levothyroxine": ["Synthroid", "Eltroxin", "Thyronorm", "Thyrox"],
            "ciprofloxacin": ["Cipro", "Levofloxacin", "Ofloxacin", "Moxifloxacin"],
            "diclofenac": ["Voltaren", "Voveran", "Diclogesic", "Diclonac"],
            "ranitidine": ["Zantac", "Aciloc", "Rantac", "Histac"],
            "dolo": ["Paracetamol", "Crocin", "Calpol", "Tylenol"],
            "crocin": ["Paracetamol", "Dolo 650", "Calpol", "Tylenol"],
            "azithromycin": ["Zithromax", "Azee", "Azithral", "Z-Pak"],
            "pantoprazole": ["Protonix", "Pantop", "Pan", "Omeprazole"]
        }

        drug = drug_name.strip().lower()

        # Check database
        if drug in alternatives_db:
            alts = alternatives_db[drug]
            result = f"üíä **Alternative Medications for {drug_name.title()}:**\n\n"
            for i, alt in enumerate(alts, 1):
                result += f"{i}. **{alt}**\n"
            result += "\n‚ö†Ô∏è **Important**: Always consult your doctor or pharmacist before switching medications. Alternatives may have different:\n"
            result += "‚Ä¢ Dosages\n‚Ä¢ Side effects\n‚Ä¢ Drug interactions\n‚Ä¢ Contraindications"
            return result

        # Use AI as fallback
        prompt = f"List 5 alternative medications for {drug_name}. Format: 1. [Drug] - [brief note]. Be concise."
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512).to(device)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=200,
                temperature=0.7,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return f"üíä **Alternatives for {drug_name}:**\n\n{response}\n\n‚ö†Ô∏è Always consult a healthcare professional."

    except Exception as e:
        return f"‚ö†Ô∏è Error: {str(e)}"

def translate_text_simple(text, target_lang):
    """Simple translation using AI model"""
    try:
        if not text.strip():
            return "‚ùå Please enter text to translate."

        if not target_lang.strip():
            return "‚ùå Please enter a target language."

        # Language names mapping
        lang_names = {
            "es": "Spanish", "fr": "French", "de": "German", "it": "Italian",
            "pt": "Portuguese", "hi": "Hindi", "zh": "Chinese", "ja": "Japanese",
            "ko": "Korean", "ru": "Russian", "ar": "Arabic", "tr": "Turkish",
            "bn": "Bengali", "ta": "Tamil", "te": "Telugu", "mr": "Marathi"
        }

        lang_code = target_lang.strip().lower()
        lang_full = lang_names.get(lang_code, target_lang)

        # Use AI model for translation
        prompt = f"Translate the following medical text to {lang_full}. Only provide the translation, nothing else.\n\nText: {text}\n\nTranslation:"

        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512).to(device)

        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=200,
                temperature=0.3,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        if "Translation:" in response:
            translation = response.split("Translation:")[-1].strip()
        else:
            translation = response.strip()

        return f"üåê **Translation to {lang_full}:**\n\n{translation}\n\n---\nüìù **Original**: {text}\n\n‚ö†Ô∏è **Note**: AI translation may not be 100% accurate. For critical medical information, use professional translation services."

    except Exception as e:
        return f"‚ö†Ô∏è Translation error: {str(e)}\n\n**Tip**: Try common codes like 'es' (Spanish), 'fr' (French), 'hi' (Hindi)"

# ========================================
# GRADIO INTERFACE
# ========================================

with gr.Blocks(theme=gr.themes.Soft(), title="Medical AI Assistant") as demo:

    gr.Markdown("""
    # üè• Medical AI Assistant
    ### Powered by IBM Granite 3.3 2B Instruct

    ‚ö†Ô∏è **Disclaimer**: Educational tool only. Always consult healthcare professionals for medical advice.
    """)

    with gr.Tabs():

        # Tab 1: Chatbot
        with gr.Tab("üí¨ Medical Chatbot"):
            gr.Markdown("### Ask medical questions and get AI-powered responses")

            chatbot = gr.Chatbot(
                height=450,
                label="Conversation",
                show_label=True
            )

            msg = gr.Textbox(
                label="Your Question",
                placeholder="Type your medical question here...",
                lines=2
            )

            with gr.Row():
                submit = gr.Button("Send üì§", variant="primary", scale=3)
                clear = gr.Button("Clear üóëÔ∏è", scale=1)

            gr.Examples(
                examples=[
                    "What are the symptoms of high blood pressure?",
                    "How can I manage diabetes with diet?",
                    "What is the difference between viral and bacterial infections?",
                    "What are common side effects of antibiotics?",
                    "How does insulin work in the body?",
                    "What foods should diabetics avoid?"
                ],
                inputs=msg,
                label="üí° Example Questions"
            )

            def respond(message, chat_history):
                bot_message = chat_with_bot(message, chat_history)
                chat_history.append((message, bot_message))
                return "", chat_history

            submit.click(respond, [msg, chatbot], [msg, chatbot])
            msg.submit(respond, [msg, chatbot], [msg, chatbot])
            clear.click(lambda: None, None, chatbot, queue=False)

        # Tab 2: Prescription Reader
        with gr.Tab("üìÑ Prescription Reader"):
            gr.Markdown("### Upload prescription images (Basic version - no OCR)")

            with gr.Row():
                with gr.Column():
                    prescription_image = gr.Image(
                        type="filepath",
                        label="Upload Prescription Image",
                        height=400
                    )
                    read_btn = gr.Button("üì∏ Process Image", variant="primary", size="lg")

                with gr.Column():
                    ocr_output = gr.Textbox(
                        label="Information",
                        lines=20,
                        placeholder="Upload an image to get instructions..."
                    )

            gr.Markdown("""
            **üìå Note**: Full OCR requires additional packages. This version provides:
            - Image upload capability
            - Manual text extraction guidance
            - Alternative methods to extract text

            **Use the chatbot** to ask questions about your prescription!
            """)

            read_btn.click(simple_ocr, prescription_image, ocr_output)

        # Tab 3: Alternative Medications
        with gr.Tab("üíä Alternative Medications"):
            gr.Markdown("### Find alternative medications and generic equivalents")

            drug_input = gr.Textbox(
                label="Enter Medication Name",
                placeholder="e.g., Paracetamol, Ibuprofen, Metformin",
                lines=1,
                scale=3
            )

            alt_btn = gr.Button("üîç Find Alternatives", variant="primary", size="lg")

            alt_output = gr.Textbox(
                label="Alternative Medications",
                lines=16,
                placeholder="Alternative medications will appear here..."
            )

            gr.Examples(
                examples=[
                    "Paracetamol",
                    "Ibuprofen",
                    "Metformin",
                    "Omeprazole",
                    "Atorvastatin",
                    "Cetirizine",
                    "Amoxicillin",
                    "Aspirin"
                ],
                inputs=drug_input,
                label="üíä Popular Medications"
            )

            alt_btn.click(suggest_alternatives, drug_input, alt_output)

        # Tab 4: Language Translation
        with gr.Tab("üåê Language Translation"):
            gr.Markdown("### Translate medical information using AI")

            with gr.Row():
                with gr.Column():
                    text_to_translate = gr.Textbox(
                        label="Text to Translate",
                        placeholder="Enter medical text in English...",
                        lines=7
                    )

                    target_language = gr.Textbox(
                        label="Target Language Code",
                        placeholder="e.g., es, fr, hi, ar",
                        value="es"
                    )

                    translate_btn = gr.Button("üåç Translate", variant="primary", size="lg")

                with gr.Column():
                    translation_output = gr.Textbox(
                        label="Translation Result",
                        lines=15,
                        placeholder="Translation will appear here..."
                    )

            gr.Markdown("""
            **Common Language Codes:**

            | Code | Language | Code | Language |
            |------|----------|------|----------|
            | `es` | Spanish | `hi` | Hindi |
            | `fr` | French | `ar` | Arabic |
            | `de` | German | `ja` | Japanese |
            | `it` | Italian | `ko` | Korean |
            | `pt` | Portuguese | `ru` | Russian |
            | `zh` | Chinese | `bn` | Bengali |

            ‚ö†Ô∏è **Note**: Uses AI-based translation. For critical medical documents, use professional translation.
            """)

            gr.Examples(
                examples=[
                    ["Take two tablets daily after meals", "es"],
                    ["Avoid alcohol while taking this medication", "fr"],
                    ["Consult your doctor if symptoms persist", "hi"],
                    ["Take on an empty stomach", "ar"]
                ],
                inputs=[text_to_translate, target_language],
                label="üìù Example Translations"
            )

            translate_btn.click(
                translate_text_simple,
                [text_to_translate, target_language],
                translation_output
            )

    gr.Markdown("""
    ---
    **‚öïÔ∏è Medical Disclaimer**: This AI assistant is for educational purposes only.

    **üö® Emergency Numbers**: 911 (US), 112 (EU), 102/108 (India)

    **üí° Technology**: IBM Granite 3.3 2B | Hugging Face Transformers | Gradio

    **üì¶ Package-Free Version**: Uses only pre-installed Colab libraries
    """)

# Launch
print("üöÄ Launching Gradio interface...")
demo.launch(share=True, debug=True)



